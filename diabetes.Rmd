---
title: "Regression"
author: "Tianyi Zhou, Mduduzi Langwenya, Shengchen Fu, Yanxi Gao, Lin Wang"
date: "3/8/2019"
output: word_document
---
### Load the packages
```{r}
library(tidyverse)
library(readr)
library(tidyverse)
library(forecast)
library(leaps)
library(forecast)
library(pROC)
library(ggplot2)
library(reshape)
library(car)
library(leaps)

rm(list=ls())

```

### Data cleaning and impution
```{r}
###import the raw diabetes data
#diabetes <- read_csv("~/My_R_Stuff/diabetes.csv")
###delete all the missing valuse
diabetes1 <- diabetes %>%
  filter( Glucose !=0 & BMI != 0 & BloodPressure != 0 & Insulin != 0 
          & SkinThickness != 0)%>%
  select(Glucose, Insulin, Outcome, BMI, SkinThickness )

##Insulin 
# stepwise for choosing models for Insulin 
insu.lm.null <- lm(Insulin~1, data = diabetes1)
insu.lm <- lm(Insulin~., data = diabetes1)

summary(insu.lm.null)
summary(insu.lm)

insu.lm.step_both <- step(insu.lm, direction = "both")
sum_both <- summary(insu.lm.step_both)

### create the model for imputing Insulin missing values
lm.data <- lm (Insulin ~ Glucose + BMI, data=diabetes1)
pred.1 <- predict (lm.data, diabetes1)

impute <-function(a, a.impute){
        ifelse(a$Insulin == 0, round(a.impute, 0), a$Insulin)
}

diabetes$newInsu <- impute(diabetes, pred.1)

#diabetes <- diabetes %>%
  #select( Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, newInsu, BMI, DiabetesPedigreeFunction, Age, Outcome)


# skinthickness 

# stepwise for choosing models for Insulin 

skin.lm.null <- lm(SkinThickness~1, data = diabetes1)
skin.lm <- lm(SkinThickness~., data = diabetes1)


skin.lm.step_both <- step(skin.lm, direction = "both")
sum_both_skin <- summary(skin.lm.step_both)


### create the model for imputing SkinThickness missing values
lm2.data <- lm(SkinThickness ~ BMI, data=diabetes1)
pred.2 <- predict (lm2.data, diabetes1)

impute <-function(a, a.impute){
  ifelse(a$SkinThickness == 0, round(a.impute, 0), a$SkinThickness)
}

diabetes$newSkin <- impute(diabetes, pred.2)

###diabetes <- diabetes %>%
  ###select( Pregnancies, Glucose, BloodPressure, SkinThickness,newInsu, Insulin, newSkin, BMI, DiabetesPedigreeFunction, Age, Outcome)
####
# diabetes <- diabetes %>%
#   select( Pregnancies, Glucose, BloodPressure, newInsu, newSkin, BMI, DiabetesPedigreeFunction, Age, Outcome)
# #write.csv(diabetes, "diabetesnew.csv")

```


#### Descriptive statistics and visualizations

```{r}
# Descriptive Statistics
melted_diabetes <- diabetes %>%
  gather(Variables, Value, -c(Pregnancies,DiabetesPedigreeFunction, Outcome, Insulin, Age))

g <- ggplot(melted_diabetes,aes(x=Value))
g <- g + geom_histogram()
g <- g + facet_wrap(~Variables)
g

# DELETE MISSING VALUES FOR OTHER VARIABLES
diabetes <- diabetes %>%
  filter(BloodPressure !=0 & BMI !=0, Glucose != 0 & newInsu != 0)

# histograms
# histograms
ggplot(diabetes, aes( x = factor(Outcome))) + 
  geom_histogram(stat = "count")

#target variable = Outcome
ggplot(diabetes, aes( x = Insulin)) + 
      geom_histogram() + 
  ggtitle("Outcome Counts")

#create age ranges 
diabetes_v <- diabetes %>%
  mutate( newAge = ifelse(Age <= 15, "0-15",
                   ifelse(Age > 15 & Age <= 30, "16-30",
                   ifelse(Age > 30 & Age <= 45, "31-45",
                   ifelse(Age > 45 & Age <= 60, "46-60","60+")))))

diabetes_v <- diabetes_v %>%
  mutate( newBMI = ifelse(BMI <= 18.5, "Underweight",
                   ifelse(BMI > 18.5 & BMI <= 25, "Normal",
                   ifelse(BMI > 25 & BMI <= 30, "Over Weight",
                          "Obese"))))

diabetes_v$newBMI=factor(diabetes_v$newBMI, 
                       levels=c("Underweight","Normal","Over Weight", "Obese"))


# boxplots glucose by Glucose
p14 <- ggplot(diabetes_v, aes(x = factor(Outcome), y = Glucose)) +
  geom_boxplot(colour = "black", fill = "#56B4E9", outline = FALSE) +
  ggtitle("BMI vs Glucose")
p14

# boxplots bloodpressure by outcome
p19 <- ggplot(diabetes_v, aes(x = factor(Outcome), y = BloodPressure)) +
  geom_boxplot(colour = "black", fill = "#56B4E9", outline = FALSE) +
  ggtitle("SkinThicknes vs BMI") 
p19


# boxplots  age by Glucose
p10 <- ggplot(diabetes_v, aes(x = newAge, y = Glucose)) +
  geom_boxplot(colour = "black", fill = "#56B4E9") +
  ggtitle("Age vs Glucose")
p10

# boxplots bmi by Glucose
p11 <- ggplot(diabetes_v, aes(x = newBMI, y = Glucose)) +
  geom_boxplot(colour = "black", fill = "#56B4E9", outline = FALSE) +
  ggtitle("BMI vs Glucose")
p11

# boxplots bmi by SkinThickness 
p12 <- ggplot(diabetes_v, aes(x = newBMI, y = SkinThickness)) +
  geom_boxplot(colour = "black", fill = "#56B4E9", outline = FALSE) +
  ggtitle("SkinThicknes vs BMI") + 
  ylim(0, 75)
p12

```

```{r}
# boxplots Age by outcome 
p16 <- ggplot(diabetes_v, aes(x = factor(Outcome), y = Age)) +
  geom_boxplot(colour = "black", fill = "#56B4E9", outline = FALSE) +
  ggtitle("SkinThicknes vs BMI") 
p16

# boxplots bmi by outcome
p17 <- ggplot(diabetes_v, aes(x = factor(Outcome), y = BMI)) +
  geom_boxplot(colour = "black", fill = "#56B4E9", outline = FALSE) +
  ggtitle("SkinThicknes vs BMI") 
p17

# boxplots pedigree by outcome
p18 <- ggplot(diabetes_v, aes(x = factor(Outcome), y = DiabetesPedigreeFunction)) +
  geom_boxplot(colour = "black", fill = "#56B4E9", outline = FALSE) +
  ggtitle("SkinThicknes vs BMI") 
p18
```


```{r}
# scatterplot age by glucose
ggplot(data = diabetes)+
  geom_point(mapping = aes(x = Age, y = Glucose))+
  geom_smooth(mapping = aes(x = Age, y = Glucose))+
  theme_bw()

# scatterplot bmi by glucose
ggplot(data = diabetes)+
  geom_point(mapping = aes(x = BMI, y = Glucose))+
  geom_smooth(mapping = aes(x = BMI, y = Glucose))+
  theme_bw()

# scatterplot DiabetesPedigreeFunction by glucose
ggplot(data = diabetes)+
  geom_point(mapping = aes(x = DiabetesPedigreeFunction, y = Glucose))+
  geom_smooth(mapping = aes(x = DiabetesPedigreeFunction, y = Glucose))+
  theme_bw()

```

```{r}
# choose log(bmi) to predict glucose, justify that choice.
ggplot(data = diabetes)+
  geom_point(mapping = aes(x = log(BMI), y = Glucose))+
  geom_smooth(mapping = aes(x = log(BMI), y = Glucose),se=FALSE)+
  theme_bw()
```

#### Regression

```{r}
################################ linear regression part #############################
set.seed(1)
randOrder2 = order(runif(nrow(diabetes)))
train.df2 = subset(diabetes,randOrder2 < .8 * nrow(diabetes))
test.df2 = subset(diabetes,randOrder2 > .8 * nrow(diabetes))

# forward
# create model with no predictors for bottom of search range
glu.lm.null <- lm(Glucose ~1, data = train.df2)
glu.lm <- lm(Glucose ~., data = train.df2)
# use step() to run forward selection
glu.lm.step_for <- step(glu.lm.null,   
                    scope=list(lower=glu.lm.null, upper=glu.lm), direction =  
                      "forward")
sum_for2 <- summary(glu.lm.step_for) 

######
Glucose ~ Outcome + Insulin + BloodPressure + Age + newInsu + 
    SkinThickness + newSkin

```

```{r}
# backward
glu.lm.step_back <- step(glu.lm, direction = "backward")
sum_back2 <- summary(glu.lm.step_back) 

#####
Glucose ~ BloodPressure + SkinThickness + Insulin + Age + Outcome + 
    newInsu + newSkin
```


```{r}
# both
glu.lm.step_both <- step(glu.lm, direction = "both")
sum_both2 <- summary(glu.lm.step_both) 

#####
Glucose ~ BloodPressure + SkinThickness + Insulin + Age + Outcome + 
    newInsu + newSkin
```

#### the best model for predict glucose
Glucose ~ BloodPressure + SkinThickness + Insulin + Age + Outcome + 
    newInsu + newSkin
```{r}
#  use options() to ensure numbers are not displayed in scientific notation.
options(scipen = 999)
Glucose_model<-lm(Glucose~BloodPressure + Age  + 
    newInsu + newSkin,data=train.df2)
summary(Glucose_model)
#check for Variance Inflation Factor (VIF); must be < 10; should be less than 5
vif(Glucose_model)

## additional diagnostics to check for outliers/leverage points
par(mfrow=c(2,2))
plot(Glucose_model)
```

#### Validation
```{r}
#### Table 6.4

# use predict() to make predictions on a new set. 
glu.lm.pred <- predict(glu.lm, test.df2)
options(scipen=999, digits = 0)
residuals <- test.df2$Glucose - glu.lm.pred
result_glu<-data.frame("Predicted" = glu.lm.pred, "Actual" = test.df2$Glucose,
           "Residual" = residuals)

options(scipen=999, digits = 3)
# use accuracy() to compute common accuracy measures.
accuracy(glu.lm.pred, test.df2$Glucose) %>% kable()




#### Table 6.5

# use regsubsets() in package leaps to run an exhaustive search. 
# unlike with lm, categorical predictors must be turned into dummies manually.

search.train2 <- regsubsets(Glucose ~ . , data = train.df2, nbest = 1, nvmax = dim(train.df2)[2],
                     method = "exhaustive")
sum_train2 <- summary(search.train2)
search.valid2 <- regsubsets(Glucose ~ . , data = test.df2, nbest = 1, nvmax = dim(test.df2)[2],
                     method = "exhaustive")
sum_test2 <- summary(search.valid2)

# show models
sum_train2$which

# show metrics
sum_train2$rsq;#sum_test2$rsq
sum_train2$adjr2
sum_train2$Cp
```

```{r}
# add high-order variable to regression
train.df2$exppedigree <- exp(train.df2$DiabetesPedigreeFunction)
train.df2$logbmi <- log(train.df2$BMI)
train.df2$logage <- log(train.df2$Age)

# new model with high-order variables
#options(scipen = 999)
Glucose_modelhi<-lm(Glucose~BloodPressure + logage +  logbmi + exppedigree+
    newInsu + newSkin,data=train.df2)
sum_hi <- summary(Glucose_modelhi)

# show metrics
sum_hi  # adjust r^2 0.238, rmse 26.01
```


```{r}
################################ logistic regression part #############################
# CHANGE DATA TYPE
diabetes$Outcome <- as.factor(diabetes$Outcome)
diabetes$Pregnancies <- as.factor(diabetes$Pregnancies)

# divide data into train and test set
set.seed(1)
randOrder = order(runif(nrow(diabetes)))
train.df = subset(diabetes,randOrder < .8 * nrow(diabetes))
test.df = subset(diabetes,randOrder > .8 * nrow(diabetes))

# forward
# create model with no predictors for bottom of search range
dia.lm.null <- glm(Outcome~1, data = train.df, family = binomial)
dia.lm <- glm(Outcome~., data = train.df, family = binomial)

# use step() to run forward selection
dia.lm.step_for <- step(dia.lm.null,   
                    scope=list(lower=dia.lm.null, upper=dia.lm), direction =  
                      "forward")
sum_for <- summary(dia.lm.step_for) 

# backward
dia.lm.step_back <- step(dia.lm, direction = "backward")
sum_back <- summary(dia.lm.step_back) 

# both
dia.lm.step_both <- step(dia.lm, direction = "both")
sum_both <- summary(dia.lm.step_both) 

# search
search <- regsubsets(Outcome ~ ., data = train.df, nbest = 1, 	nvmax = dim(train.df)[2], method = "exhaustive")
sum_sear <-summary(search)
sum_sear$which;
sum_sear$rsq;
sum_sear$adjr2;
sum_sear$Cp;


# comparison 
# same models with different methods
sum_for$coefficients
sum_back$coefficients
sum_both$coefficients

# best model with aic 536.4962
sum_for$aic

# Prediction on test data and accuracy test (73.1%)
tst_pred <- ifelse(predict(dia.lm.step_for, newdata = test.df, type = "response") > 0.5, "Yes", "No")
tst_tab <- table(predicted = tst_pred, actual = test.df$Outcome); sum(diag(tst_tab))/sum(tst_tab)
test_prob <- predict(dia.lm.step_for, newdata = test.df, type = "response")
test_roc <- roc(test.df$Outcome ~ test_prob, plot = TRUE, print.auc = TRUE) # 0.774

```
